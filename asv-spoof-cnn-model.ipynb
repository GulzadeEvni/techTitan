{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3842332,"sourceType":"datasetVersion","datasetId":2286778}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport tensorflow.keras as keras\nimport matplotlib.pyplot as plt\nimport librosa\nimport os\nimport math\nimport shutil\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-01-25T22:15:30.894275Z","iopub.execute_input":"2024-01-25T22:15:30.895085Z","iopub.status.idle":"2024-01-25T22:15:30.900435Z","shell.execute_reply.started":"2024-01-25T22:15:30.895047Z","shell.execute_reply":"2024-01-25T22:15:30.899458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_PATH = '/kaggle/input/asvpoof-2019-dataset/LA/LA'","metadata":{"execution":{"iopub.status.busy":"2024-01-25T22:15:37.594524Z","iopub.execute_input":"2024-01-25T22:15:37.594996Z","iopub.status.idle":"2024-01-25T22:15:37.599590Z","shell.execute_reply.started":"2024-01-25T22:15:37.594960Z","shell.execute_reply":"2024-01-25T22:15:37.598659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(f'{BASE_PATH}/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt',\n                       sep=\" \", header=None)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T22:15:39.330245Z","iopub.execute_input":"2024-01-25T22:15:39.330991Z","iopub.status.idle":"2024-01-25T22:15:39.370679Z","shell.execute_reply.started":"2024-01-25T22:15:39.330955Z","shell.execute_reply":"2024-01-25T22:15:39.369809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T22:15:41.900984Z","iopub.execute_input":"2024-01-25T22:15:41.901782Z","iopub.status.idle":"2024-01-25T22:15:41.913703Z","shell.execute_reply.started":"2024-01-25T22:15:41.901745Z","shell.execute_reply":"2024-01-25T22:15:41.912642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.columns =['speaker_id','filename','system_id','null','class_name']\ntrain_df.drop(columns=['null'],inplace=True)\ntrain_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T22:15:44.821779Z","iopub.execute_input":"2024-01-25T22:15:44.822446Z","iopub.status.idle":"2024-01-25T22:15:44.835500Z","shell.execute_reply.started":"2024-01-25T22:15:44.822414Z","shell.execute_reply":"2024-01-25T22:15:44.834386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['filepath'] = f'{BASE_PATH}/ASVspoof2019_LA_train/flac/'+train_df.filename+'.flac'\ntrain_df['target'] = (train_df.class_name=='spoof').astype('int32')\nprint('len Train', len(train_df))\ntrain_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T22:15:47.342555Z","iopub.execute_input":"2024-01-25T22:15:47.342995Z","iopub.status.idle":"2024-01-25T22:15:47.376552Z","shell.execute_reply.started":"2024-01-25T22:15:47.342964Z","shell.execute_reply":"2024-01-25T22:15:47.375265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\n\n# Önceden oluşturulmuş klasörleri kontrol et ve gerekiyorsa oluştur\noutput_folder_0 = './0'  # Klasör adı 0\noutput_folder_1 = './1'  # Klasör adı 1\n\nif not os.path.exists(output_folder_0):\n    os.makedirs(output_folder_0)\n\nif not os.path.exists(output_folder_1):\n    os.makedirs(output_folder_1)\n\n# Train veri çerçevesini dön ve dosyaları ilgili klasörlere kopyala\nfor index, row in train_df.iterrows():\n    source_filepath = row['filepath']\n    target_folder = f'./{row[\"target\"]}'\n    target_filepath = os.path.join(target_folder, os.path.basename(source_filepath))\n\n    # Hedef klasörü kontrol et ve gerekiyorsa oluştur\n    if not os.path.exists(target_folder):\n        os.makedirs(target_folder)\n\n    # Dosyayı hedef klasöre kopyala\n    shutil.copy(source_filepath, target_filepath)\n\n# İşlem tamamlandıktan sonra oluşturulan klasörleri kontrol etmek için kullanabilirsiniz\nprint(f'0 Klasöründe {len(os.listdir(output_folder_0))} dosya var.')\nprint(f'1 Klasöründe {len(os.listdir(output_folder_1))} dosya var.')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-25T22:16:57.175318Z","iopub.execute_input":"2024-01-25T22:16:57.175716Z","iopub.status.idle":"2024-01-25T22:17:03.296913Z","shell.execute_reply.started":"2024-01-25T22:16:57.175684Z","shell.execute_reply":"2024-01-25T22:17:03.295981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folder_path = './0' \n\nfiles = os.listdir(folder_path)\n\ntotal_files = len(files)\n\nprint(f\"Klasörde toplam {total_files} dosya var.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-01-25T22:18:51.843682Z","iopub.execute_input":"2024-01-25T22:18:51.844086Z","iopub.status.idle":"2024-01-25T22:18:51.851838Z","shell.execute_reply.started":"2024-01-25T22:18:51.844054Z","shell.execute_reply":"2024-01-25T22:18:51.850787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n\nfolder_path = './1'  # Değiştirmeniz gereken klasör yolu\n\nfiles = os.listdir(folder_path)\n\ntotal_files = len(files)\n\nprint(f\"Klasörde toplam {total_files} dosya var.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-01-25T22:18:59.090225Z","iopub.execute_input":"2024-01-25T22:18:59.090608Z","iopub.status.idle":"2024-01-25T22:18:59.109957Z","shell.execute_reply.started":"2024-01-25T22:18:59.090567Z","shell.execute_reply":"2024-01-25T22:18:59.109092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\nfolder_path = './0'  # Değiştirmeniz gereken klasör yolu\n\nfiles = os.listdir(folder_path)\n\ntotal_files = len(files)\n\n# Silinecek dosya sayısı\nnum_files_to_delete = 1580\n\nfiles_to_delete = random.sample(files, min(num_files_to_delete, total_files))\n\nfor file_name in files_to_delete:\n    file_path = os.path.join(folder_path, file_name)\n    try:\n        os.remove(file_path)\n        print(f\"{file_name} dosyası silindi.\")\n    except Exception as e:\n        print(f\"Hata silinirken: {e}\")\n\nremaining_files = os.listdir(folder_path)\nprint(f\"Klasörde kalan toplam {len(remaining_files)} dosya var.\")","metadata":{"execution":{"iopub.status.busy":"2024-01-25T22:20:03.994349Z","iopub.execute_input":"2024-01-25T22:20:03.994738Z","iopub.status.idle":"2024-01-25T22:20:04.086779Z","shell.execute_reply.started":"2024-01-25T22:20:03.994708Z","shell.execute_reply":"2024-01-25T22:20:04.085773Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\nfolder_path = './1' \n\nfiles = os.listdir(folder_path)\n\ntotal_files = len(files)\n\n# Silinecek dosya sayısı\nnum_files_to_delete = 21800\n\nfiles_to_delete = random.sample(files, min(num_files_to_delete, total_files))\n\nfor file_name in files_to_delete:\n    file_path = os.path.join(folder_path, file_name)\n    try:\n        os.remove(file_path)\n        print(f\"{file_name} dosyası silindi.\")\n    except Exception as e:\n        print(f\"Hata silinirken: {e}\")\n\nremaining_files = os.listdir(folder_path)\nprint(f\"Klasörde kalan toplam {len(remaining_files)} dosya var.\")","metadata":{"execution":{"iopub.status.busy":"2024-01-25T22:21:10.915755Z","iopub.execute_input":"2024-01-25T22:21:10.916584Z","iopub.status.idle":"2024-01-25T22:21:12.055664Z","shell.execute_reply.started":"2024-01-25T22:21:10.916520Z","shell.execute_reply":"2024-01-25T22:21:12.054560Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\n\nsource_folders = ['0', '1']\n\n# Hedef klasörün adı\ntarget_folder = 'audio'\n\nif not os.path.exists(target_folder):\n    os.makedirs(target_folder)\n\nfor source_folder in source_folders:\n    source_folder_path = os.path.join('.', source_folder)\n    target_folder_path = os.path.join(target_folder, source_folder)\n\n    # Kaynak klasörü var mı diye kontrol et\n    if os.path.exists(source_folder_path):\n        # Hedef klasörü oluştur\n        if not os.path.exists(target_folder_path):\n            os.makedirs(target_folder_path)\n\n        # Kaynak klasöründeki dosyaları hedef klasöre taşı\n        for file_name in os.listdir(source_folder_path):\n            source_file_path = os.path.join(source_folder_path, file_name)\n            target_file_path = os.path.join(target_folder_path, file_name)\n\n            try:\n                shutil.move(source_file_path, target_file_path)\n                print(f\"{file_name} dosyası {source_folder} klasöründen {target_folder}/{source_folder} klasörüne taşındı.\")\n            except Exception as e:\n                print(f\"Hata taşınırken: {e}\")\n    else:\n        print(f\"{source_folder} klasörü bulunamadı.\")\n\nprint(f\"İşlem tamamlandı. '{target_folder}' klasöründe şu dosyalar var:\")\nprint(os.listdir(target_folder))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-25T22:24:36.115793Z","iopub.execute_input":"2024-01-25T22:24:36.116186Z","iopub.status.idle":"2024-01-25T22:24:36.208526Z","shell.execute_reply.started":"2024-01-25T22:24:36.116158Z","shell.execute_reply":"2024-01-25T22:24:36.207520Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATASET_PATH = \"/kaggle/working/audio\"\nJSON_PATH = \"data.json\"\nSAMPLE_RATE = 22050\nTRACK_DURATION = 30 \nSAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n\n\ndef save_mfcc(dataset_path, json_path, num_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):\n\n    \n    data = {\n        \"mapping\": [],\n        \"labels\": [],\n        \"mfcc\": []\n    }\n\n    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n\n    \n    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n\n        \n        if dirpath is not dataset_path:\n\n            \n            semantic_label = dirpath.split(\"/\")[-1]\n            data[\"mapping\"].append(semantic_label)\n            print(\"\\nProcessing: {}\".format(semantic_label))\n\n           \n            for f in filenames:\n\n                file_path = os.path.join(dirpath, f)\n                signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n\n                \n                for d in range(num_segments):\n\n                    \n                    start = samples_per_segment * d\n                    finish = start + samples_per_segment\n\n                    # mfcc çıkar\n                    mfcc = librosa.feature.mfcc(y=signal[start:finish], sr=sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n                    mfcc = mfcc.T\n\n                    \n                    if len(mfcc) == num_mfcc_vectors_per_segment:\n                        data[\"mfcc\"].append(mfcc.tolist())\n                        data[\"labels\"].append(i-1)\n                        print(\"{}, segment:{}\".format(file_path, d+1))\n\n    #  MFCCs leri json olarak kaydet\n    with open(json_path, \"w\") as fp:\n        json.dump(data, fp, indent=4)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-25T22:25:25.294238Z","iopub.execute_input":"2024-01-25T22:25:25.295013Z","iopub.status.idle":"2024-01-25T22:25:25.308411Z","shell.execute_reply.started":"2024-01-25T22:25:25.294977Z","shell.execute_reply":"2024-01-25T22:25:25.307339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    save_mfcc(DATASET_PATH, JSON_PATH, num_segments=10)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T22:25:35.474663Z","iopub.execute_input":"2024-01-25T22:25:35.475324Z","iopub.status.idle":"2024-01-25T22:29:02.528039Z","shell.execute_reply.started":"2024-01-25T22:25:35.475292Z","shell.execute_reply":"2024-01-25T22:29:02.527152Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nDATA_PATH = \"/kaggle/working/data.json\"\n\n\ndef load_data(data_path):\n\n    with open(data_path, \"r\") as fp:\n        data = json.load(fp)\n\n    X = np.array(data[\"mfcc\"])\n    y = np.array(data[\"labels\"])\n    return X, y\n\n\ndef plot_history(history):\n\n    fig, axs = plt.subplots(2)\n\n    \n    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n    axs[0].set_ylabel(\"Accuracy\")\n    axs[0].legend(loc=\"lower right\")\n    axs[0].set_title(\"Accuracy eval\")\n\n    \n    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n    axs[1].set_ylabel(\"Error\")\n    axs[1].set_xlabel(\"Epoch\")\n    axs[1].legend(loc=\"upper right\")\n    axs[1].set_title(\"Error eval\")\n\n    plt.show()\n\n\ndef prepare_datasets(test_size, validation_size):\n\n    \n    X, y = load_data(DATA_PATH)\n\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n\n    \n    X_train = X_train[..., np.newaxis]\n    X_validation = X_validation[..., np.newaxis]\n    X_test = X_test[..., np.newaxis]\n\n    return X_train, X_validation, X_test, y_train, y_validation, y_test\n\n\ndef build_model(input_shape):\n\n    \n    model = keras.Sequential()\n\n    # 1st conv layer\n    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n    model.add(keras.layers.BatchNormalization())\n\n    # 2nd conv layer\n    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n    model.add(keras.layers.BatchNormalization())\n\n    # 3rd conv layer\n    model.add(keras.layers.Conv2D(32, (2, 2), activation='relu'))\n    model.add(keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n    model.add(keras.layers.BatchNormalization())\n\n    \n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dense(64, activation='relu'))\n    model.add(keras.layers.Dropout(0.3))\n\n    # output layer\n    model.add(keras.layers.Dense(2, activation='softmax'))\n\n    return model\n\n\ndef predict(model, X, y):\n\n    \n    X = X[np.newaxis, ...] # array shape (1, 130, 13, 1)\n\n    \n    prediction = model.predict(X)\n\n    \n    predicted_index = np.argmax(prediction, axis=1)\n\n    print(\"Target: {}, Predicted label: {}\".format(y, predicted_index))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-25T22:29:58.538995Z","iopub.execute_input":"2024-01-25T22:29:58.539796Z","iopub.status.idle":"2024-01-25T22:29:58.558956Z","shell.execute_reply.started":"2024-01-25T22:29:58.539762Z","shell.execute_reply":"2024-01-25T22:29:58.557956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n\n    \n    X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(0.25, 0.2)\n\n    \n    \n    input_shape = (130, 13, 1)\n    model = build_model(input_shape)\n\n    \n    optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n    model.compile(optimizer=optimiser,\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n\n    model.summary()\n\n    history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=30)\n\n    \n    plot_history(history)\n\n    \n    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n    print('\\nTest accuracy:', test_acc)\n\n    \n    X_to_predict = X_test[100]\n    y_to_predict = y_test[100]\n\n    \n    predict(model, X_to_predict, y_to_predict)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-25T22:30:43.302343Z","iopub.execute_input":"2024-01-25T22:30:43.303094Z","iopub.status.idle":"2024-01-25T22:31:00.697435Z","shell.execute_reply.started":"2024-01-25T22:30:43.303060Z","shell.execute_reply":"2024-01-25T22:31:00.696380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Modeli kaydet\nmodel.save(\"/kaggle/working/cnn_audio.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-01-25T22:31:58.541385Z","iopub.execute_input":"2024-01-25T22:31:58.542159Z","iopub.status.idle":"2024-01-25T22:31:58.614716Z","shell.execute_reply.started":"2024-01-25T22:31:58.542109Z","shell.execute_reply":"2024-01-25T22:31:58.613746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-25T22:49:08.619528Z","iopub.execute_input":"2024-01-25T22:49:08.619928Z","iopub.status.idle":"2024-01-25T22:49:08.662508Z","shell.execute_reply.started":"2024-01-25T22:49:08.619897Z","shell.execute_reply":"2024-01-25T22:49:08.661614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2024-01-25T22:32:25.669847Z","iopub.execute_input":"2024-01-25T22:32:25.670287Z","iopub.status.idle":"2024-01-25T22:32:25.676342Z","shell.execute_reply.started":"2024-01-25T22:32:25.670251Z","shell.execute_reply":"2024-01-25T22:32:25.675268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_voice(model, audio_file_path, genre_mapping):\n\n    \n    signal, sample_rate = librosa.load(audio_file_path, sr=22050)\n\n    \n    mfcc = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=13, n_fft=2048, hop_length=512)\n    mfcc = mfcc.T\n\n    # MFCC'leri uygun boyuta getir\n    mfcc = np.resize(mfcc, (130, 13, 1))\n\n    # Reshape MFCC'leri uygun boyuta gwtir\n    mfcc = mfcc[np.newaxis, ...]\n\n   \n    prediction = model.predict(mfcc)\n    predicted_index = np.argmax(prediction, axis=1)\n\n    \n    genre_label = genre_mapping[predicted_index[0]]\n    print(\"Raw prediction:\", prediction)\n\n    return genre_label\n\n\nmodel_path = \"/kaggle/working/cnn_audio.h5\"\nmodel = load_model(model_path)\n\n\naudio_file_path = \"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_eval/flac/LA_E_1001232.flac\"\n\ngenre_mapping = {0: \"real\", 1: \"fake\"}\n\n\npredicted_voice = predict_voice(model, audio_file_path, genre_mapping)\n\nprint(\"Predicted genre:\", predicted_voice)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-25T23:15:24.748658Z","iopub.execute_input":"2024-01-25T23:15:24.749716Z","iopub.status.idle":"2024-01-25T23:15:25.221578Z","shell.execute_reply.started":"2024-01-25T23:15:24.749677Z","shell.execute_reply":"2024-01-25T23:15:25.220640Z"},"trusted":true},"execution_count":null,"outputs":[]}]}